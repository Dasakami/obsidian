# wb-suppliers-bot — проект (реализация)

Полная заготовка проекта Telegram-бота для поиска поставщиков Wildberries. Включены: Docker, docker-compose, схема БД, асинхронный бот на `python-telegram-bot`, работа с Postgres (`asyncpg`), модульный код (handlers / services / db / config), заготовки скрейперов для Rusprofile/Kartoteka/Контур.Фокус и логика кэширования.

> **Важно:** это рабочая заготовка — части парсеров (особенно для коммерческих сайтов) помечены комментариями и требуют аккуратной настройки под реальные HTML-структуры, учёта rate-limit и легальности доступа.

---

## Структура проекта (файлы в документе)

```
wb-suppliers-bot/
├─ docker-compose.yml
├─ Dockerfile
├─ requirements.txt
├─ .env.example
├─ db/
│  └─ init.sql
└─ src/
   └─ app/
      ├─ __init__.py
      ├─ main.py
      ├─ config.py
      ├─ logging_conf.py
      ├─ db/
      │  ├─ __init__.py
      │  ├─ pool.py
      │  └─ repo.py
      ├─ handlers/
      │  ├─ __init__.py
      │  ├─ start.py
      │  └─ link_handler.py
      └─ services/
         ├─ __init__.py
         ├─ wb_client.py
         ├─ scraper_clients.py
         └─ contacts_service.py
```

---

## Как использовать

1. Скопируй репозиторий.
    
2. Создай файл `.env` по образцу `.env.example`.
    
3. `docker compose up --build` — поднимет Postgres и бота.
    
4. В Telegram отправь боту ссылку на товар Wildberries — бот попытается найти поставщика и вернуть имя, ИНН/ОГРН, адрес, сайт и email (если найдётся).
    

---

## Файлы и код

### `Dockerfile`

```dockerfile
FROM python:3.11-slim

ENV PYTHONUNBUFFERED=1
WORKDIR /app

# системные зависимости для сборки bs4, lxml, asyncpg
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential gcc libpq-dev curl netcat && \
    rm -rf /var/lib/apt/lists/*

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

# Копируем код
COPY src/ ./src/
COPY db/init.sql ./db/init.sql

WORKDIR /app/src

CMD ["python", "-m", "app.main"]
```

---

### `docker-compose.yml`

```yaml
version: '3.8'
services:
  db:
    image: postgres:15
    environment:
      POSTGRES_DB: wb_suppliers
      POSTGRES_USER: wb_user
      POSTGRES_PASSWORD: wb_pass
    volumes:
      - db_data:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    ports:
      - "5432:5432"

  bot:
    build: .
    depends_on:
      - db
    environment:
      - BOT_TOKEN=${BOT_TOKEN}
      - DATABASE_URL=postgresql://wb_user:wb_pass@db:5432/wb_suppliers
      - LOG_LEVEL=INFO
    restart: unless-stopped

volumes:
  db_data:
```

---

### `requirements.txt`

```
python-dotenv>=1.0.0
pydantic>=1.10
python-telegram-bot>=20.0
aiohttp>=3.8
asyncpg>=0.27
beautifulsoup4>=4.12
lxml>=4.9
requests>=2.28
```

---

### `.env.example`

```
BOT_TOKEN=123456:ABC-DEF
DATABASE_URL=postgresql://wb_user:wb_pass@localhost:5432/wb_suppliers
LOG_LEVEL=INFO
```

---

### `db/init.sql`

```sql
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";

CREATE TABLE IF NOT EXISTS suppliers (
  id SERIAL PRIMARY KEY,
  inn VARCHAR(32) UNIQUE,
  ogrn VARCHAR(32),
  name TEXT NOT NULL,
  source TEXT,
  raw jsonb,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS contacts (
  id SERIAL PRIMARY KEY,
  supplier_id INTEGER REFERENCES suppliers(id) ON DELETE CASCADE,
  site TEXT,
  email TEXT,
  address TEXT,
  raw jsonb,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE IF NOT EXISTS lookups (
  id SERIAL PRIMARY KEY,
  supplier_id INTEGER REFERENCES suppliers(id),
  nm_id BIGINT,
  query TEXT,
  status TEXT,
  source TEXT,
  raw jsonb,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS ix_suppliers_inn ON suppliers(inn);
CREATE INDEX IF NOT EXISTS ix_lookups_nm_id ON lookups(nm_id);
```

---

### `src/app/__init__.py`

```py
# package marker
```

---

### `src/app/config.py`

```py
from pydantic import BaseSettings

class Settings(BaseSettings):
    BOT_TOKEN: str
    DATABASE_URL: str
    LOG_LEVEL: str = "INFO"

    class Config:
        env_file = "../../.env"
        env_file_encoding = "utf-8"

settings = Settings()
```

> Примечание: `env_file` указан относительно `src/app` — в Dockerfile рабочая директория установлена в `/app/src`.

---

### `src/app/logging_conf.py`

```py
import logging
import sys

def configure_logging(level: str = "INFO"):
    level = getattr(logging, level.upper(), logging.INFO)
    root = logging.getLogger()
    root.setLevel(level)

    handler = logging.StreamHandler(sys.stdout)
    handler.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(name)s: %(message)s"))
    root.handlers = [handler]
```

---

### `src/app/db/pool.py`

```py
import asyncpg
import asyncio
from app.config import settings
import logging

_pool: asyncpg.pool.Pool | None = None
logger = logging.getLogger(__name__)

async def init_pool():
    global _pool
    if _pool is None:
        logger.info("Creating asyncpg pool")
        _pool = await asyncpg.create_pool(dsn=settings.DATABASE_URL, min_size=1, max_size=5)
    return _pool

async def get_pool():
    if _pool is None:
        return await init_pool()
    return _pool
```

---

### `src/app/db/repo.py`

```py
import json
import logging
from app.db.pool import get_pool

logger = logging.getLogger(__name__)

async def get_supplier_by_inn(inn: str):
    pool = await get_pool()
    async with pool.acquire() as conn:
        row = await conn.fetchrow("SELECT * FROM suppliers WHERE inn=$1", inn)
        return dict(row) if row else None

async def get_supplier_by_name(name: str):
    pool = await get_pool()
    async with pool.acquire() as conn:
        row = await conn.fetchrow("SELECT * FROM suppliers WHERE lower(name)=lower($1)", name)
        return dict(row) if row else None

async def create_supplier(inn: str | None, ogrn: str | None, name: str, source: str, raw: dict):
    pool = await get_pool()
    async with pool.acquire() as conn:
        row = await conn.fetchrow(
            "INSERT INTO suppliers(inn, ogrn, name, source, raw) VALUES($1,$2,$3,$4,$5) RETURNING *",
            inn, ogrn, name, source, json.dumps(raw)
        )
        return dict(row)

async def create_contact(supplier_id: int, site: str | None, email: str | None, address: str | None, raw: dict):
    pool = await get_pool()
    async with pool.acquire() as conn:
        row = await conn.fetchrow(
            "INSERT INTO contacts(supplier_id, site, email, address, raw) VALUES($1,$2,$3,$4,$5) RETURNING *",
            supplier_id, site, email, address, json.dumps(raw)
        )
        return dict(row)

async def create_lookup(supplier_id: int | None, nm_id: int | None, query: str, status: str, source: str | None, raw: dict | None = None):
    pool = await get_pool()
    async with pool.acquire() as conn:
        row = await conn.fetchrow(
            "INSERT INTO lookups(supplier_id, nm_id, query, status, source, raw) VALUES($1,$2,$3,$4,$5,$6) RETURNING *",
            supplier_id, nm_id, query, status, source, json.dumps(raw) if raw else None
        )
        return dict(row)
```

---

### `src/app/handlers/start.py`

```py
from telegram import Update
from telegram.ext import ContextTypes

async def start_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = (
        "Привет! Отправь ссылку на товар Wildberries, и я постараюсь найти поставщика:\n"
        "— я попытаюсь извлечь название поставщика и ИНН/ОГРН из карточки товара, затем найду открытые данные (Rusprofile/Kartoteka/Контур).\n"
        "Пример: https://www.wildberries.ru/catalog/12345678/detail.aspx"
    )
    await update.message.reply_text(msg)
```

---

### `src/app/handlers/link_handler.py`

```py
import logging
import re
from telegram import Update
from telegram.ext import ContextTypes
from app.services.wb_client import extract_supplier_from_link
from app.services.contacts_service import find_or_lookup_supplier

logger = logging.getLogger(__name__)

WB_NM_RE = re.compile(r"(?:catalog/)?(?P<nm>\d{5,})")

async def link_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    text = (update.message.text or "").strip()
    nm_match = WB_NM_RE.search(text)
    nm_id = int(nm_match.group('nm')) if nm_match else None

    await update.message.chat.send_action(action="typing")

    try:
        wb_info = await extract_supplier_from_link(text, nm_id)
    except Exception as e:
        logger.exception("wb parse error")
        await update.message.reply_text("Не удалось разобрать ссылку Wildberries — пожалуйста, пришлите прямой URL или nm_id.")
        return

    # wb_info: { 'name': ..., 'inn': ..., 'ogrn': ..., 'nm_id': ... }
    result = await find_or_lookup_supplier(wb_info)

    if not result:
        await update.message.reply_text("Поставщик не найден в открытых источниках.")
        return

    # Формируем ответ
    parts = []
    parts.append(f"Поставщик: {result.get('name')}")
    if result.get('inn'):
        parts.append(f"ИНН: {result.get('inn')}")
    if result.get('ogrn'):
        parts.append(f"ОГРН: {result.get('ogrn')}")
    if result.get('address'):
        parts.append(f"Адрес: {result.get('address')}")
    if result.get('site'):
        parts.append(f"Сайт: {result.get('site')}")
    if result.get('email'):
        parts.append(f"Email: {result.get('email')}")

    parts.append("\n(Телефон не предоставляется легально)")

    await update.message.reply_text("\n".join(parts))
```

---

### `src/app/services/wb_client.py`

```py
import re
import aiohttp
import logging
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)

NM_RE = re.compile(r"(?:catalog/)?(\d{5,})")

async def extract_supplier_from_link(link: str, nm_id: int | None = None) -> dict:
    # Попытаться извлечь nm_id из ссылки, если не передан
    if not nm_id:
        m = NM_RE.search(link)
        if m:
            nm_id = int(m.group(1))

    if not nm_id:
        raise ValueError("nm_id не найден в ссылке")

    # Попытаться получить JSON карточки через публичный WB endpoint (heuristic)
    try:
        url = f"https://card.wb.ru/cards/detail?nm={nm_id}&locale=ru"
        async with aiohttp.ClientSession() as sess:
            async with sess.get(url, timeout=10) as resp:
                if resp.status == 200:
                    data = await resp.json(content_type=None)
                    # структура может меняться; смотрим в data
                    supplier_name = None
                    inn = None
                    ogrn = None
                    # Ищем по типичным полям в JSON
                    try:
                        card = data.get('data', {}).get('products', [])[0]
                        supplier_name = card.get('supplier') or card.get('brand') or card.get('seller')
                        # некоторые карточки имеют vendor info
                        if not supplier_name:
                            supplier_name = card.get('name')
                    except Exception:
                        pass

                    # Если не получили INN — fallback к HTML
                    if supplier_name:
                        return { 'nm_id': nm_id, 'name': supplier_name, 'inn': inn, 'ogrn': ogrn }
    except Exception as e:
        logger.debug("WB JSON endpoint failed: %s", e)

    # Fallback: парсим страницу товара
    page_url = f"https://www.wildberries.ru/catalog/{nm_id}/detail.aspx"
    async with aiohttp.ClientSession() as sess:
        async with sess.get(page_url, timeout=10) as resp:
            if resp.status != 200:
                raise RuntimeError(f"WB page request failed {resp.status}")
            text = await resp.text()
            soup = BeautifulSoup(text, "lxml")

            # Попытка найти имя поставщика в тексте страницы
            # Ищем по признакам: 'поставщик', 'Продавец', 'ИП'
            text_search = soup.get_text(separator='\n')
            # простая эвристика
            for line in text_search.splitlines():
                if 'поставщик' in line.lower() or 'продавец' in line.lower() or 'производитель' in line.lower():
                    # берем строку и очищаем
                    candidate = line.strip()
                    if len(candidate) > 3:
                        return { 'nm_id': nm_id, 'name': candidate, 'inn': None, 'ogrn': None }

    # если ничего не нашли
    return { 'nm_id': nm_id, 'name': None, 'inn': None, 'ogrn': None }
```

---

### `src/app/services/scraper_clients.py`

```py
import aiohttp
from bs4 import BeautifulSoup
import logging

logger = logging.getLogger(__name__)

async def search_rusprofile_by_inn(inn: str) -> dict | None:
    # Простая реализация: посетить страницу https://www.rusprofile.ru/inquiry/<inn>
    url = f"https://www.rusprofile.ru/search?query={inn}"
    async with aiohttp.ClientSession() as sess:
        async with sess.get(url, timeout=15) as resp:
            if resp.status != 200:
                return None
            text = await resp.text()
            soup = BeautifulSoup(text, 'lxml')
            # На странице поиска есть блоки результатов — ниже только пример, нужно адаптировать
            res = {}
            # Попробуем найти structured data / ld+json
            ld = soup.find('script', type='application/ld+json')
            if ld:
                try:
                    import json
                    data = json.loads(ld.string)
                    # извлечь название и адрес
                    name = data.get('name')
                    address = None
                    if isinstance(data.get('address'), dict):
                        address = data['address'].get('streetAddress')
                    res.update({'name': name, 'address': address, 'site': None, 'email': None, 'raw': data})
                    return res
                except Exception:
                    pass
            # fallback: парсинг результатов
            # ...
            return None

async def search_rusprofile_by_name(name: str) -> dict | None:
    # аналогично, поиск по имени
    return await search_rusprofile_by_inn(name)

async def search_kartoteka(query: str) -> dict | None:
    # пример: https://kartoteka.ru/search/?q=<query>
    url = f"https://kartoteka.ru/search/?q={query}"
    async with aiohttp.ClientSession() as sess:
        async with sess.get(url, timeout=15) as resp:
            if resp.status != 200:
                return None
            text = await resp.text()
            soup = BeautifulSoup(text, 'lxml')
            # TODO: конкретная логика парсинга
            return None

async def search_contour_focus(query: str) -> dict | None:
    # Контур.Фокус часто имеет paywall; здесь - заглушка
    return None
```

> **Важно:** настоящие HTML-структуры сайтов меняются; адаптируй селекторы под актуальную разметку, соблюдай `robots.txt` и правила использования.

---

### `src/app/services/contacts_service.py`

```py
import logging
import asyncio
from app.db import repo
from app.services.scraper_clients import search_rusprofile_by_inn, search_rusprofile_by_name, search_kartoteka, search_contour_focus

logger = logging.getLogger(__name__)

async def find_or_lookup_supplier(wb_info: dict) -> dict | None:
    """
    Основная логика:
    - если в wb_info есть INN — проверить кэш в БД
    - если найден в кэше — вернуть
    - иначе выполнить поиск в источниках, сохранить и вернуть
    """
    name = wb_info.get('name')
    inn = wb_info.get('inn')
    nm_id = wb_info.get('nm_id')

    # 1) если есть INN — попробовать найти в БД
    if inn:
        existing = await repo.get_supplier_by_inn(inn)
        if existing:
            # записываем lookup
            await repo.create_lookup(existing['id'], nm_id, inn, 'SUCCESS', 'cache')
            # дополним контактами
            pool = await repo.get_pool() if hasattr(repo, 'get_pool') else None
            # готовим ответ
            contact_rows = None
            # простая агрегация
            return {
                'name': existing['name'],
                'inn': existing['inn'],
                'ogrn': existing.get('ogrn'),
                # далее можно дополнять контактами
            }

    # 2) Если INN нет или не найден — искать в источниках
    queries = []
    if inn:
        queries.append(('rusprofile', search_rusprofile_by_inn, inn))
    if name:
        queries.append(('rusprofile_name', search_rusprofile_by_name, name))
        queries.append(('kartoteka', search_kartoteka, name))
        queries.append(('contour', search_contour_focus, name))

    # Параллельно выполнять запросы с таймаутом
    tasks = [asyncio.create_task(func(q)) for (_, func, q) in queries]
    done, pending = await asyncio.wait(tasks, timeout=12)

    best = None
    for t in done:
        try:
            res = t.result()
            if res:
                best = res
                break
        except Exception:
            logger.exception('scraper error')

    for p in pending:
        p.cancel()

    if not best:
        await repo.create_lookup(None, nm_id, name or inn or str(nm_id), 'NOT_FOUND', None)
        return None

    # Сохраняем поставщика и контакты
    supplier = await repo.create_supplier(best.get('inn'), best.get('ogrn'), best.get('name') or name or 'Unknown', 'scraper', best.get('raw') or {})
    await repo.create_contact(supplier['id'], best.get('site'), best.get('email'), best.get('address'), best.get('raw') or {})
    await repo.create_lookup(supplier['id'], nm_id, name or inn or str(nm_id), 'SUCCESS', 'scraper', best.get('raw'))

    return {
        'name': supplier['name'],
        'inn': supplier['inn'],
        'ogrn': supplier['ogrn'],
        'address': best.get('address'),
        'site': best.get('site'),
        'email': best.get('email')
    }
```

---

### `src/app/main.py`

```py
import logging
import asyncio
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters
from app.config import settings
from app.logging_conf import configure_logging
from app.handlers.start import start_handler
from app.handlers.link_handler import link_handler
from app.db.pool import init_pool

async def main():
    configure_logging(settings.LOG_LEVEL)

    # Инициализируем пул подключений к БД заранее
    await init_pool()

    app = ApplicationBuilder().token(settings.BOT_TOKEN).build()

    app.add_handler(CommandHandler('start', start_handler))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, link_handler))

    # Запуск polling
    await app.initialize()
    await app.start()
    await app.updater.start_polling()
    # Ограничение: бот будет работать пока контейнер жив
    await app.updater.idle()

if __name__ == '__main__':
    asyncio.run(main())
```

> Примечание: Варианты запуска `python -m app.main` и `Application.run_polling()` можно менять — в докер-файле и примерах используется асинхронная инициализация пулов.

---

## Что ещё можно добавить / улучшить

1. **Queue / очередь задач (Celery / RQ)** — полезно, если парсинг занимает много времени или требует ретраев.
    
2. **Админ-панель** — просматривать кэшированные поставщики, ручная коррекция.
    
3. **Более устойчивые скрейперы** — использовать headless browser (Playwright) для динамических страниц, но аккуратно с нагрузкой/legality.
    
4. **Тесты и CI** — unit/integration тесты для repo и сервисов.
    
5. **Рейты/бэк-офф** при обращениях к внешним ресурсам, прокси и rotate user-agent.
    
6. **Логирование запросов и метрик** (Prometheus/Grafana).
    

---

Если хочешь, могу:

- добавить реализацию конкретных парсеров для Rusprofile/Kartoteka (я сгенерирую конкретные CSS-селекторы и JSON-ld обработку),
    
- сделать Docker-compose для продакшена с секретами,
    
- написать unit-тесты для `repo` и `wb_client`.
    

Готово — весь код и структура созданы в этом документе. Открой документ и скажи, что делать дальше: наполнить парсеры, добавить Celery, или собрать образ и протестировать локально.